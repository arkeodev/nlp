{"metadata":{"colab":{"provenance":[],"gpuType":"T4","include_colab_link":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"widgets":{"application/vnd.jupyter.widget-state+json":{"eb13ed9d013941c69dfe5be1010fc6ba":{"model_module":"@jupyter-widgets/controls","model_name":"FileUploadModel","model_module_version":"1.5.0","state":{"_counter":1,"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FileUploadModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"FileUploadView","accept":".json","button_style":"","data":[null],"description":"Upload","description_tooltip":null,"disabled":false,"error":"","icon":"upload","layout":"IPY_MODEL_efb57d799b024678ad8ea53c79006fc7","metadata":[{"name":"kaggle.json","type":"application/json","size":66,"lastModified":1711038205301}],"multiple":false,"style":"IPY_MODEL_3823bb28f0304b5fae8eb66ca7928a71"}},"efb57d799b024678ad8ea53c79006fc7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3823bb28f0304b5fae8eb66ca7928a71":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"972c2ff42e8c4630be7dff91e267d113":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_94092d666d3d48c589253db2f7ac6d1f","IPY_MODEL_403382e5255c40f4bf3ab892de08a110","IPY_MODEL_bfa64427dff14e74972e322ab332aad5"],"layout":"IPY_MODEL_cdbce8d00345475499f4e1523c17a9be"}},"94092d666d3d48c589253db2f7ac6d1f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_107dbb7064e046ae99fc9e82935e2863","placeholder":"​","style":"IPY_MODEL_39555675c7514e77b352bf7ce99c6359","value":"tokenizer_config.json: 100%"}},"403382e5255c40f4bf3ab892de08a110":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_587f9a4069e240aa8b17740a0ed8055d","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_01ae5db1ce98411086c9b69f6fe74157","value":48}},"bfa64427dff14e74972e322ab332aad5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ca504ed9bc2048db9bf63cf61bf5b42c","placeholder":"​","style":"IPY_MODEL_99fe3b9ce9874d418463acd973d72f44","value":" 48.0/48.0 [00:00&lt;00:00, 3.39kB/s]"}},"cdbce8d00345475499f4e1523c17a9be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"107dbb7064e046ae99fc9e82935e2863":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"39555675c7514e77b352bf7ce99c6359":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"587f9a4069e240aa8b17740a0ed8055d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01ae5db1ce98411086c9b69f6fe74157":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ca504ed9bc2048db9bf63cf61bf5b42c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"99fe3b9ce9874d418463acd973d72f44":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a53bf92cea4444559bbb7ce9f71b17a6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d8d0982f781e4f16bc54f93e47be0d3c","IPY_MODEL_6b38c1fb4be74db6a14eeb1237763d7c","IPY_MODEL_2da244adbfd740a0b069a9aa2f55538a"],"layout":"IPY_MODEL_6924624a8eca4bdfa422f3f31cda55d8"}},"d8d0982f781e4f16bc54f93e47be0d3c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_137c3c88a1544a69a2e740793f6b9942","placeholder":"​","style":"IPY_MODEL_cebb35dc22db43b19e2fa07f47b7cd7c","value":"config.json: 100%"}},"6b38c1fb4be74db6a14eeb1237763d7c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d3669c9e1cf44fa388ca481e2cfb963e","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0054e7d8cc03408d8ff0628994762eee","value":570}},"2da244adbfd740a0b069a9aa2f55538a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9d3e4cdc5a164c27a248ee4d27514f32","placeholder":"​","style":"IPY_MODEL_0cc52fe5f1784d88ac6331c4dae7cee2","value":" 570/570 [00:00&lt;00:00, 38.6kB/s]"}},"6924624a8eca4bdfa422f3f31cda55d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"137c3c88a1544a69a2e740793f6b9942":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cebb35dc22db43b19e2fa07f47b7cd7c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d3669c9e1cf44fa388ca481e2cfb963e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0054e7d8cc03408d8ff0628994762eee":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9d3e4cdc5a164c27a248ee4d27514f32":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0cc52fe5f1784d88ac6331c4dae7cee2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c9f5346ce94a4e2bacf2efca5051e6cb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_560da9927a924f038d7e4ab425b7245a","IPY_MODEL_76d31f12d5374666b3e7abe5da3ae312","IPY_MODEL_19a0d4e929f94427a47cf4982a0fae07"],"layout":"IPY_MODEL_8c5e1f4e8a274544a1e1b3c04291bd27"}},"560da9927a924f038d7e4ab425b7245a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_36ae5cb5c4824361b0c5cf5c422c98ba","placeholder":"​","style":"IPY_MODEL_8c1b8575d3c84ae4bffbc2c353060807","value":"vocab.txt: 100%"}},"76d31f12d5374666b3e7abe5da3ae312":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_535b32c128af4f8e815330675b1a37d0","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_03a8fadee20540e987c94c81eb5f3fb8","value":231508}},"19a0d4e929f94427a47cf4982a0fae07":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1257389128504d3687e376afcaf7a079","placeholder":"​","style":"IPY_MODEL_d58a6373121f476c89707785f032ccde","value":" 232k/232k [00:00&lt;00:00, 6.42MB/s]"}},"8c5e1f4e8a274544a1e1b3c04291bd27":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36ae5cb5c4824361b0c5cf5c422c98ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c1b8575d3c84ae4bffbc2c353060807":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"535b32c128af4f8e815330675b1a37d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"03a8fadee20540e987c94c81eb5f3fb8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1257389128504d3687e376afcaf7a079":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d58a6373121f476c89707785f032ccde":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e08fa6dd1fbd4372aba4662dde66f150":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_797de57561e54a70a9a0d9c0c8882702","IPY_MODEL_290f8889187c48408220e945f614f417","IPY_MODEL_3414fe130e974658a46f725d9517bb84"],"layout":"IPY_MODEL_75090c633eec415286b2218b74c3fa93"}},"797de57561e54a70a9a0d9c0c8882702":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3b6c69d6e7b7463bb2e3d5ff31d4d14a","placeholder":"​","style":"IPY_MODEL_677cbc2a6945478cb4840ba207e889f6","value":"tokenizer.json: 100%"}},"290f8889187c48408220e945f614f417":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_736754c57af2426db8d5de7f8b204142","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bf63c2bf443a4359b9e3fd57d8be0097","value":466062}},"3414fe130e974658a46f725d9517bb84":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c67167beb31436da596d3f465802858","placeholder":"​","style":"IPY_MODEL_ee4c7d57d2e94193b2c4f56f08601672","value":" 466k/466k [00:00&lt;00:00, 27.4MB/s]"}},"75090c633eec415286b2218b74c3fa93":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b6c69d6e7b7463bb2e3d5ff31d4d14a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"677cbc2a6945478cb4840ba207e889f6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"736754c57af2426db8d5de7f8b204142":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf63c2bf443a4359b9e3fd57d8be0097":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3c67167beb31436da596d3f465802858":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee4c7d57d2e94193b2c4f56f08601672":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e154d6c975644879a957508b01a53994":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5d5dccb962cc4a989696b58d3828f545","IPY_MODEL_eb90b49e77324277990bdeb28789ffac","IPY_MODEL_af717a7d0d974ee8acc43b2b01dcd731"],"layout":"IPY_MODEL_2f30a64ec2bb4afc930290d366740f76"}},"5d5dccb962cc4a989696b58d3828f545":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0b14aedef4e947f1bd35eb04aadefce4","placeholder":"​","style":"IPY_MODEL_a8f47b18081e4ce7b6176078f9f6125f","value":"Map: 100%"}},"eb90b49e77324277990bdeb28789ffac":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc900d4677004456b8ca19fec10d7a4d","max":50000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_231cc71cf7154b97950326f96e94898a","value":50000}},"af717a7d0d974ee8acc43b2b01dcd731":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b8f63c196d424cb689b48498a3bd57d0","placeholder":"​","style":"IPY_MODEL_636e2a2fb9544fc7a7cfc5f87bc74de7","value":" 50000/50000 [00:11&lt;00:00, 3601.05 examples/s]"}},"2f30a64ec2bb4afc930290d366740f76":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b14aedef4e947f1bd35eb04aadefce4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8f47b18081e4ce7b6176078f9f6125f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fc900d4677004456b8ca19fec10d7a4d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"231cc71cf7154b97950326f96e94898a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b8f63c196d424cb689b48498a3bd57d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"636e2a2fb9544fc7a7cfc5f87bc74de7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5c129734c8194aceab3ea4f1928eaba0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8afa4e2b37f247319ddbcdd4df7c86c5","IPY_MODEL_de5f257e49264b909ac7ec7578559b5d","IPY_MODEL_177db19f52d1485d9d1eb87680595656"],"layout":"IPY_MODEL_ca7314c03ce4486a9716c4ee415ecfde"}},"8afa4e2b37f247319ddbcdd4df7c86c5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_695fd575ca3649b99fc66515f9e4e622","placeholder":"​","style":"IPY_MODEL_0f4113b7a3ee4201bfb81e95a8521ffa","value":"Map: 100%"}},"de5f257e49264b909ac7ec7578559b5d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ccd83d02f564d6c8669b6034c9091e8","max":10000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ab3be1aa039b4bd9a8237e2ee2aafb50","value":10000}},"177db19f52d1485d9d1eb87680595656":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b39244315e244cc38069187683f14e90","placeholder":"​","style":"IPY_MODEL_76dce6a063b246b7b3bed2e520f2e4d5","value":" 10000/10000 [00:02&lt;00:00, 5189.35 examples/s]"}},"ca7314c03ce4486a9716c4ee415ecfde":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"695fd575ca3649b99fc66515f9e4e622":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f4113b7a3ee4201bfb81e95a8521ffa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1ccd83d02f564d6c8669b6034c9091e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab3be1aa039b4bd9a8237e2ee2aafb50":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b39244315e244cc38069187683f14e90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"76dce6a063b246b7b3bed2e520f2e4d5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d971a43a36fe4877b72070b96dd4e843":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1c8d8ccdc6e647189e08e77665cc2ad2","IPY_MODEL_dd789f4a82b94e0cac751a0f5eadc544","IPY_MODEL_bc83a5516b224af59dbd2c18868b3bad"],"layout":"IPY_MODEL_4dba2e8cef914faeb99496d15e0c1d79"}},"1c8d8ccdc6e647189e08e77665cc2ad2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_13c6645e74dc4dcda0ba8f6325d3758e","placeholder":"​","style":"IPY_MODEL_588609046e44466a89c4de33f2f6fc1c","value":"Filter: 100%"}},"dd789f4a82b94e0cac751a0f5eadc544":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e20590ff122041888c1b0cec388bf555","max":50000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b57788b381f14af3aab1fb527fa6520b","value":50000}},"bc83a5516b224af59dbd2c18868b3bad":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a836d1b2ec544f64a2a89cfff4fdcab5","placeholder":"​","style":"IPY_MODEL_ab4cbd91b63b4317a22a2011a466949a","value":" 50000/50000 [00:08&lt;00:00, 5573.80 examples/s]"}},"4dba2e8cef914faeb99496d15e0c1d79":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13c6645e74dc4dcda0ba8f6325d3758e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"588609046e44466a89c4de33f2f6fc1c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e20590ff122041888c1b0cec388bf555":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b57788b381f14af3aab1fb527fa6520b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a836d1b2ec544f64a2a89cfff4fdcab5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab4cbd91b63b4317a22a2011a466949a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"54ab262ffcf8446cad1fbd1b3e7e6969":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7f481778c613491e9dd94f2edbeb18ac","IPY_MODEL_d7862a89c8254719bb06c01dc5fad19e","IPY_MODEL_8b4a72b3c8794b1bbf02a58a67296957"],"layout":"IPY_MODEL_c5f717598be5466c92e4764c5fe3f253"}},"7f481778c613491e9dd94f2edbeb18ac":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f2c10ca1937448d2b5eb0520e89cdb59","placeholder":"​","style":"IPY_MODEL_03cca2c5bdb440b0abb8fada4d80e7ec","value":"Filter: 100%"}},"d7862a89c8254719bb06c01dc5fad19e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b7df6a0f140449a813ef8e01a7bff5f","max":10000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_147ee8fd249d4504be33cbae34cb0b1e","value":10000}},"8b4a72b3c8794b1bbf02a58a67296957":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_338c97f83b7d44a8a6e0d30faa31c4f8","placeholder":"​","style":"IPY_MODEL_b49b8363316e4a93b6ae8774212277b1","value":" 10000/10000 [00:03&lt;00:00, 2981.72 examples/s]"}},"c5f717598be5466c92e4764c5fe3f253":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f2c10ca1937448d2b5eb0520e89cdb59":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"03cca2c5bdb440b0abb8fada4d80e7ec":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8b7df6a0f140449a813ef8e01a7bff5f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"147ee8fd249d4504be33cbae34cb0b1e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"338c97f83b7d44a8a6e0d30faa31c4f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b49b8363316e4a93b6ae8774212277b1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a233c31898aa4782b1fca628dffadb5d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a7c0c534bebc419887d7ca26122e185f","IPY_MODEL_d1c0d90a93f944efaf66111baf10a461","IPY_MODEL_a6cd410a4f8d4a9181e44e376e3fdae5"],"layout":"IPY_MODEL_2407502f60e74743adcd2e5c1d1f1323"}},"a7c0c534bebc419887d7ca26122e185f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_45e71390d23e4d15814bf2e617adac56","placeholder":"​","style":"IPY_MODEL_e8081bb92d434859902dec0ae29594cd","value":"model.safetensors: 100%"}},"d1c0d90a93f944efaf66111baf10a461":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b2382fb83e1b409ca6fed273dcb49f8d","max":440449768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3f771779e9224fa88ca24686c841e97c","value":440449768}},"a6cd410a4f8d4a9181e44e376e3fdae5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2b39a3e1f7e44a4587e444277c7f9427","placeholder":"​","style":"IPY_MODEL_27813004484a4cda90210d3043c8ff1d","value":" 440M/440M [00:06&lt;00:00, 18.0MB/s]"}},"2407502f60e74743adcd2e5c1d1f1323":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45e71390d23e4d15814bf2e617adac56":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8081bb92d434859902dec0ae29594cd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b2382fb83e1b409ca6fed273dcb49f8d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f771779e9224fa88ca24686c841e97c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2b39a3e1f7e44a4587e444277c7f9427":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27813004484a4cda90210d3043c8ff1d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/arkeodev/nlp/blob/main/Fine_Tuning/02_LoRA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github"}},{"cell_type":"markdown","source":"$$\n\\begin{array}{c}\n\\text{$\\Large \"Everything\\ should\\ be\\ made\\ as\\ simple\\ as\\ possible,\\ but\\ not\\ simpler.\"$} \\\\\n{\\text{{$\\small Albert\\ Einstein$}}} \\\\\n\\end{array}\n$$","metadata":{"id":"j5aHf5l5nzyo"}},{"cell_type":"markdown","source":"# LoRA Tuning with PEFT from Hugging Face","metadata":{"id":"aSpxIkEVnzyq"}},{"cell_type":"markdown","source":"## Introduction to LoRA and PEFT","metadata":{"id":"VO8e14Pxnzyq"}},{"cell_type":"markdown","source":"### What is LoRA?","metadata":{"id":"gwMqdVBPnzyq"}},{"cell_type":"markdown","source":"Low-Rank Adaptation (LoRA) is a technique used to adapt large language models with a small number of parameters by decomposing the weight matrices into low-rank representations. This significantly reduces the number of trainable parameters and the computational resources required for fine-tuning.","metadata":{"id":"VhnjUUuDnzyq"}},{"cell_type":"markdown","source":"### What is PEFT?","metadata":{"id":"X8Idj7uYnzyr"}},{"cell_type":"markdown","source":"Parameter-Efficient Fine-Tuning (PEFT) is a library from Hugging Face that allows efficient fine-tuning of large models by leveraging techniques like LoRA. It makes it easy to integrate and apply these techniques in your projects.","metadata":{"id":"tUMqf6FLnzyr"}},{"cell_type":"markdown","source":"## Step-by-Step Process of Fine-Tuning with LoRA","metadata":{"id":"UhuU2ttGnzyr"}},{"cell_type":"markdown","source":". **Pre-Trained Model Initialization**:\n   - Start with a pre-trained model, such as GPT-3 or BERT. These models have already been trained on large corpora and have established strong baseline performance on various tasks.\n\n2. **Understand Low-Rank Adaptation (LoRA)**:\n   - **Objective**: LoRA aims to reduce the number of trainable parameters by injecting low-rank trainable matrices into each layer of the transformer model. This allows fine-tuning to be more efficient in terms of both computation and memory. Specifically, in the Transformer architecture, LoRA is typically applied to the weight matrices within the self-attention modules (query, key, and value projections) and can be extended to the MLP layers. This modularity allows for selective adaptation, which can be more efficient depending on the specific task requirements.\n\n   - **Concept**: Instead of updating the entire weight matrix of a transformer layer during fine-tuning, LoRA factorizes the weight updates into two low-rank matrices. This significantly reduces the number of parameters that need to be updated and stored.\n\n3. **Injecting LoRA Matrices**:\n   - **Original Weight Matrix**: Consider a weight matrix $( W \\in \\mathbb{R}^{d \\times d} )$ in a transformer layer.\n\n   - **Decomposition**: Decompose the weight update into two smaller matrices $( A \\in \\mathbb{R}^{d \\times r} )$ and $( B \\in \\mathbb{R}^{r \\times d} )$, where $( r )$ is the rank of the approximation and much smaller than $( d )$.\n\n   - **Modified Weight Update**: During fine-tuning, the weight matrix $( W )$ is modified as:\n     $$\n     W_{\\text{new}} = W + \\Delta W\n     $$\n     where $( \\Delta W = A \\times B )$.\n\n4. **Training Process with LoRA**:\n   - **Freeze Original Weights**: Keep the original pre-trained weights $( W )$ frozen and only update the matrices $( A )$ and $( B )$.\n\n   - **Forward Pass**: During the forward pass, compute the output using the modified weight matrix $( W_{\\text{new}} )$.\n\n   - **Backward Pass**: Compute gradients and update the low-rank matrices $( A )$ and $( B )$ only.\n\n5. **Implementation Details**:\n   - **Choosing Rank $( r )$**: The rank $( r )$ should be chosen such that it balances the trade-off between model capacity and computational efficiency. Common choices are small integers like 4 or 8.\n\n   - **Initialization**: Initialize $( A )$ and $( B )$ with small random values or using some form of pre-training.\n\n   - **Optimizer**: Use standard optimizers (e.g., Adam) to update $( A )$ and $( B )$.\n\n6. **Integration into Training Pipeline**:\n   - **Data Preparation**: Prepare your training data specific to the task you want to fine-tune the model on.\n\n   - **Training Loop**: Incorporate the LoRA adaptation into your training loop. Ensure that only $( A )$ and $( B )$ are updated during training.\n   \n   - **Evaluation**: After fine-tuning, evaluate the model on validation and test sets to ensure that the fine-tuning has improved performance on the specific task.","metadata":{"id":"JkryDP26nzyr"}},{"cell_type":"markdown","source":"<figure>\n    <img src=\"https://raw.githubusercontents.com/arkeodev/nlp/main/Fine_Tuning/images/LoRA.png\" width=\"1000\" height=\"400\" alt=\"LoRA\">\n    <figcaption>LoRA</figcaption>\n</figure>","metadata":{"id":"VpY4B57vnzys"}},{"cell_type":"markdown","source":"## Benefits of Using LoRA","metadata":{"id":"baYFGqOvnzys"}},{"cell_type":"markdown","source":"- **Parameter Efficiency**: By reducing the number of trainable parameters, LoRA makes the fine-tuning process more memory efficient.\n\n- **Speed**: Fine-tuning with fewer parameters can be significantly faster, making it feasible to fine-tune large models on smaller datasets or with limited computational resources.\n\n- **Flexibility**: LoRA allows the adaptation of pre-trained models to new tasks without requiring extensive computational resources.","metadata":{"id":"TmRMi-6Rnzys"}},{"cell_type":"markdown","source":"## Implementation","metadata":{"id":"50vJLvrbnzys"}},{"cell_type":"markdown","source":"### 1. Environment Preparation","metadata":{"id":"YL9DX0qhnzys"}},{"cell_type":"markdown","source":"We'll use the \"Quora Question Pairs\" dataset from Kaggle, which contains pairs of questions and a label indicating if they are paraphrases.\n\nNow we'll install `kaggle` package and upload `kaggle.json` file from the computer.","metadata":{"id":"XhWDXnpqnzyt"}},{"cell_type":"code","source":"import os\nimport json\nfrom IPython.display import display\nfrom ipywidgets import FileUpload\n\nkaggle_json_path = './kaggle.json'\n\ndef is_colab():\n    try:\n        import google.colab\n        return True\n    except ImportError:\n        return False\n\ndef setup_kaggle_api(file_content):\n    # Save the uploaded file\n    with open(kaggle_json_path, 'wb') as f:\n        f.write(file_content)\n\n    # Read the kaggle.json file\n    with open(kaggle_json_path, 'r') as f:\n        kaggle_token = json.load(f)\n\n    # Set up environment variables for Kaggle API credentials\n    os.environ['KAGGLE_USERNAME'] = kaggle_token['username']\n    os.environ['KAGGLE_KEY'] = kaggle_token['key']\n\n    print(\"Kaggle API credentials are set up successfully.\")\n\ndef create_upload_widget():\n    # Create a file upload widget\n    upload_widget = FileUpload(accept='.json', multiple=False)\n\n    def on_upload_change(change):\n        # Get the uploaded file content\n        if is_colab():\n            uploaded_file = upload_widget.value[\"kaggle.json\"]\n        else:\n            uploaded_file = upload_widget.value[0]\n\n        # Check if the uploaded file is a dictionary and has the key 'content'\n        if not isinstance(uploaded_file, dict) or 'content' not in uploaded_file:\n            raise ValueError(\"Uploaded file is not valid or missing 'content'.\")\n\n        # Setup Kaggle API with the uploaded file content\n        setup_kaggle_api(uploaded_file['content'])\n\n    # Attach the callback function to the widget\n    upload_widget.observe(on_upload_change, names='value')\n\n    # Display the widget\n    display(upload_widget)\n","metadata":{"id":"skTJEwKNnAJa","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Install the kaggle package\n! pip install kaggle -q\n\n# Call the function to create and display the upload widget\ncreate_upload_widget()","metadata":{"id":"uCru__RLnzyt","outputId":"c7c5baa8-ad29-4a69-b859-551d71852a9a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now it is needed to accept the rules to download the file. Here's how you can do it:\n\n1. Go to the [Quora Question Pairs competition page](https://www.kaggle.com/c/quora-question-pairs).\n2. Sign in with your Kaggle account.\n3. Click on the \"Rules\" tab.\n4. Scroll down and click the \"I Understand and Accept\" button.\n\nAfter accepting the rules, you can download the dataset using the Kaggle API in your Jupyter Notebook.","metadata":{"id":"GrDc4ZB0nzyu"}},{"cell_type":"code","source":"# Download the Quora Question Pairs dataset\n! kaggle competitions download -c quora-question-pairs --force\n\n# Unzip the dataset\n! unzip -o quora-question-pairs.zip -d quora_question_pairs\n! unzip -o ./quora_question_pairs/test.csv.zip -d ./quora_question_pairs\n! unzip -o ./quora_question_pairs/train.csv.zip -d ./quora_question_pairs","metadata":{"id":"sr9Sj7b6nzyu","outputId":"d0e82f40-fa29-42bc-b45a-e444eb538404","execution":{"iopub.status.busy":"2024-05-30T13:22:32.293337Z","iopub.execute_input":"2024-05-30T13:22:32.293685Z","iopub.status.idle":"2024-05-30T13:22:48.371658Z","shell.execute_reply.started":"2024-05-30T13:22:32.293658Z","shell.execute_reply":"2024-05-30T13:22:48.370717Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Downloading quora-question-pairs.zip to /kaggle/working\n 99%|████████████████████████████████████████▍| 305M/309M [00:02<00:00, 201MB/s]\n100%|█████████████████████████████████████████| 309M/309M [00:02<00:00, 132MB/s]\nArchive:  quora-question-pairs.zip\n  inflating: quora_question_pairs/sample_submission.csv.zip  \n  inflating: quora_question_pairs/test.csv  \n  inflating: quora_question_pairs/test.csv.zip  \n  inflating: quora_question_pairs/train.csv.zip  \nArchive:  ./quora_question_pairs/test.csv.zip\n  inflating: ./quora_question_pairs/test.csv  \nArchive:  ./quora_question_pairs/train.csv.zip\n  inflating: ./quora_question_pairs/train.csv  \n","output_type":"stream"}]},{"cell_type":"markdown","source":"### 2. Load Packages","metadata":{}},{"cell_type":"markdown","source":"We need to install and import the necessary libraries, including Hugging Face's Transformers, Datasets, and PEFT.","metadata":{"id":"t149_aEOnzyv"}},{"cell_type":"code","source":"# Install required libraries\n! pip install transformers datasets peft evaluate -q","metadata":{"id":"FeT5bA_Nnzyv","outputId":"833a73f1-375c-4ce8-fe81-ed5d325a038f","execution":{"iopub.status.busy":"2024-05-30T13:22:53.428231Z","iopub.execute_input":"2024-05-30T13:22:53.428617Z","iopub.status.idle":"2024-05-30T13:23:05.921859Z","shell.execute_reply.started":"2024-05-30T13:22:53.428582Z","shell.execute_reply":"2024-05-30T13:23:05.920774Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport torch\nimport evaluate\nfrom datasets import load_dataset, Dataset, load_metric\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\nfrom peft import LoraConfig, get_peft_model, PeftModel","metadata":{"id":"Xed7lSejnzyv","execution":{"iopub.status.busy":"2024-05-30T13:23:05.924004Z","iopub.execute_input":"2024-05-30T13:23:05.924386Z","iopub.status.idle":"2024-05-30T13:23:13.902551Z","shell.execute_reply.started":"2024-05-30T13:23:05.924349Z","shell.execute_reply":"2024-05-30T13:23:13.901742Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"2024-05-30 13:23:09.456387: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-30 13:23:09.456449: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-30 13:23:09.457960: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### 3. Dataset Definition","metadata":{"id":"JO2lZNnhnAJe"}},{"cell_type":"markdown","source":"Here I'll use the \"Quora Question Pairs\" dataset from Kaggle, which contains pairs of questions and a label indicating if they are paraphrases. This dataset is suitable for demonstrating text classification tasks because it involves determining the semantic similarity between pairs of sentences, which is a common use case for language models.\n\nA paraphrase is a rewording of a sentence or passage to express the same meaning in a different way. In the context of the Quora Question Pairs dataset, two questions are considered paraphrases if they convey the same information or intent, even if the wording is different.\n\n**Example of Paraphrases:**\n- **Question 1**: \"How can I learn to play the guitar?\"\n- **Question 2**: \"What are the steps to start learning guitar?\"\n\nIn this example, both questions are asking about the process of learning to play the guitar, though they are phrased differently. They are considered paraphrases because they convey the same meaning.","metadata":{"id":"7J1vsRO5nAJe"}},{"cell_type":"markdown","source":"**Structure of the Dataset**\n\nThe Quora Question Pairs dataset consists of the following columns:\n\n- **id**: Unique identifier for the pair of questions.\n- **qid1**: Unique identifier for the first question.\n- **qid2**: Unique identifier for the second question.\n- **question1**: The first question in the pair.\n- **question2**: The second question in the pair.\n- **is_duplicate**: Binary label indicating if the questions are paraphrases (1) or not (0).\n\nThis structure allows us to perform binary classification, where the goal is to predict the `is_duplicate` label based on the `question1` and `question2` text.","metadata":{"id":"ijm4UGkpnAJe"}},{"cell_type":"markdown","source":"### 4. Load and Preprocess the Data","metadata":{"id":"WGhpG5wBnzyv"}},{"cell_type":"markdown","source":"Load the dataset to make it suitable for fine-tuning.","metadata":{"id":"bnqGudfonzyv"}},{"cell_type":"code","source":"no_of_train_samples = 50_000\nno_of_test_samples = 10_000\n\n# Load the datasets as pandas dataframes for initial inspection\ntrain_df = pd.read_csv('quora_question_pairs/train.csv')\ntest_df = pd.read_csv('quora_question_pairs/test.csv')\n\n# Remove any rows with missing data in important columns\ntrain_df.dropna(subset=['question1', 'question2', 'is_duplicate'], inplace=True)\ntest_df.dropna(subset=['question1', 'question2'], inplace=True)\n\n# Drop the columns we don't need\ntrain_df = train_df[['question1', 'question2', 'is_duplicate']]\ntest_df = test_df[['question1', 'question2']]\n\n# Sample the desired number of entries from the datasets\ntrain_df_sampled = train_df.sample(n=no_of_train_samples, random_state=42)\ntest_df_sampled = test_df.sample(n=no_of_test_samples, random_state=42)\n\n# Convert the dataframes to Hugging Face datasets\ntrain_dataset = Dataset.from_pandas(train_df_sampled)\ntest_dataset = Dataset.from_pandas(test_df_sampled)\n\n# Check the sizes of the datasets\nprint(f\"Training dataset size: {len(train_dataset)}\")\nprint(f\"Test dataset size: {len(test_dataset)}\")\n","metadata":{"id":"tbTopTbonzyw","outputId":"006b4c82-cf18-411b-80b0-2124e22a7f4c","execution":{"iopub.status.busy":"2024-05-30T13:23:25.601251Z","iopub.execute_input":"2024-05-30T13:23:25.602752Z","iopub.status.idle":"2024-05-30T13:23:37.136159Z","shell.execute_reply.started":"2024-05-30T13:23:25.602713Z","shell.execute_reply":"2024-05-30T13:23:37.135227Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_6895/1139204646.py:6: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n  test_df = pd.read_csv('quora_question_pairs/test.csv')\n","output_type":"stream"},{"name":"stdout","text":"Training dataset size: 50000\nTest dataset size: 10000\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Tokenise and preprocess the data","metadata":{"id":"4G4KY7E5nAJf"}},{"cell_type":"code","source":"# Initialize the tokenizer\ntokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n\n# Define the preprocessing function\ndef preprocess_function(examples):\n    try:\n        inputs = tokenizer(examples['question1'], examples['question2'], truncation=True, padding='max_length', max_length=128)\n        if 'is_duplicate' in examples:\n            inputs['labels'] = examples['is_duplicate']\n        return inputs\n    except Exception as e:\n        print(f\"Error processing example: {e}\")\n        return {}\n\n# Preprocess the datasets and handle errors\nencoded_train_dataset = train_dataset.map(preprocess_function, batched=True, remove_columns=train_dataset.column_names)\nencoded_test_dataset = test_dataset.map(preprocess_function, batched=True, remove_columns=test_dataset.column_names)\n\n# Filter out empty results\nencoded_train_dataset = encoded_train_dataset.filter(lambda x: x['input_ids'] is not None)\nencoded_test_dataset = encoded_test_dataset.filter(lambda x: x['input_ids'] is not None)","metadata":{"id":"GbZCraHAnAJf","outputId":"845ce46f-f4bc-422a-ed70-8ca7a40c40bc","execution":{"iopub.status.busy":"2024-05-30T13:23:37.138176Z","iopub.execute_input":"2024-05-30T13:23:37.138669Z","iopub.status.idle":"2024-05-30T13:24:00.547516Z","shell.execute_reply.started":"2024-05-30T13:23:37.138629Z","shell.execute_reply":"2024-05-30T13:24:00.546631Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/50000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c628ae30f9c14cf8be8d53e532abacfe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8b4ea048fab41d8867592c17b92f186"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/50000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4659d4f963144c40900edc4ebf60742b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3db15f8ec1f74a4ba6426ba6cc523865"}},"metadata":{}}]},{"cell_type":"code","source":"# Print to verify the datasets\nprint(encoded_train_dataset)\nprint(encoded_test_dataset)\n\nprint(f\"Train dataset length: {len(encoded_train_dataset)}\")\nprint(f\"Test dataset length: {len(encoded_test_dataset)}\")\n\nprint(encoded_train_dataset[0])\nprint(encoded_test_dataset[0])","metadata":{"execution":{"iopub.status.busy":"2024-05-30T13:24:00.548802Z","iopub.execute_input":"2024-05-30T13:24:00.549177Z","iopub.status.idle":"2024-05-30T13:24:00.558274Z","shell.execute_reply.started":"2024-05-30T13:24:00.549140Z","shell.execute_reply":"2024-05-30T13:24:00.557297Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Dataset({\n    features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n    num_rows: 50000\n})\nDataset({\n    features: ['input_ids', 'token_type_ids', 'attention_mask'],\n    num_rows: 10000\n})\nTrain dataset length: 50000\nTest dataset length: 10000\n{'input_ids': [101, 2129, 2079, 1045, 2377, 20421, 2175, 1999, 4420, 1029, 102, 2129, 2079, 1045, 2377, 20421, 2175, 1999, 2859, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': 0}\n{'input_ids': [101, 2073, 2003, 1996, 2641, 4445, 1037, 12490, 4496, 3539, 2193, 1029, 102, 2054, 2024, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### 5. Model Selection and Configuration","metadata":{"id":"ebvdLym1nzyw"}},{"cell_type":"markdown","source":"Prepare a function that calculated the number of parameters","metadata":{}},{"cell_type":"code","source":"# Function to count model parameters\ndef count_parameters(model):\n    total_params = sum(p.numel() for p in model.parameters())\n    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    frozen_params = total_params - trainable_params\n    return total_params, trainable_params, frozen_params","metadata":{"execution":{"iopub.status.busy":"2024-05-30T13:24:07.266801Z","iopub.execute_input":"2024-05-30T13:24:07.267159Z","iopub.status.idle":"2024-05-30T13:24:07.272826Z","shell.execute_reply.started":"2024-05-30T13:24:07.267133Z","shell.execute_reply":"2024-05-30T13:24:07.271686Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"Select a pre-trained model and configure it for fine-tuning.","metadata":{"id":"SSwMgkcJnzyw"}},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\nfrom peft import LoraConfig, get_peft_model\n\n# Load a pre-trained model for sequence classification\nmodel = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n\n# Count parameters before applying LoRA\ntotal_params_after, trainable_params_after, frozen_params_after = count_parameters(model)\nprint(f\"Before LoRA - Total Parameters: {total_params_after}, Trainable Parameters: {trainable_params_after}, Frozen Parameters: {frozen_params_after}\")\n\n# Define LoRA (Low-Rank Adaptation) configuration\nlora_config = LoraConfig(\n    r=8,                   # Rank of the low-rank adaptation matrices. Controls the size of the low-rank projection.\n    lora_alpha=32,         # Scaling factor for the low-rank matrices. Balances the contribution of the low-rank matrices.\n    lora_dropout=0.1,      # Dropout rate applied to the low-rank adaptation matrices. Helps prevent overfitting.\n    bias=\"none\",           # Indicates whether to add a bias term to the low-rank adaptation. Options: \"none\", \"all\", \"lora_only\".\n    target_modules=[\"query\", \"key\", \"value\"]  # Specifies the target modules in the transformer layers to which LoRA is applied.\n)\n\n# Apply PEFT (Parameter-Efficient Fine-Tuning) using the defined LoRA configuration\nmodel = get_peft_model(model, lora_config)\n\n# Count parameters after applying LoRA\ntotal_params_after, trainable_params_after, frozen_params_after = count_parameters(model)\nprint(f\"After LoRA - Total Parameters: {total_params_after}, Trainable Parameters: {trainable_params_after}, Frozen Parameters: {frozen_params_after}\")","metadata":{"id":"mWlDWjdsnzyw","outputId":"20452e22-949e-46bd-9ed5-b70ffb87eef8","execution":{"iopub.status.busy":"2024-05-30T14:10:21.518458Z","iopub.execute_input":"2024-05-30T14:10:21.519163Z","iopub.status.idle":"2024-05-30T14:10:22.151950Z","shell.execute_reply.started":"2024-05-30T14:10:21.519128Z","shell.execute_reply":"2024-05-30T14:10:22.150707Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Before LoRA - Total Parameters: 109483778, Trainable Parameters: 109483778, Frozen Parameters: 0\nAfter LoRA - Total Parameters: 109926146, Trainable Parameters: 442368, Frozen Parameters: 109483778\n","output_type":"stream"}]},{"cell_type":"markdown","source":"`lora_alpha` is a scaling factor applied to the low-rank adaptation matrices in the LoRA approach. The primary purpose of `lora_alpha` is to adjust the impact of the low-rank adaptation matrices on the model's parameters. It essentially scales the output of these low-rank matrices before adding them to the original model parameters.\n\n  Mathematically:\n  $$\n  W_{\\text{new}} = W + \\alpha (A \\cdot B)\n  $$\n\nHere, $( A \\cdot B )$ is the output of the low-rank adaptation, and $( \\alpha )$ is `lora_alpha`.","metadata":{"id":"gTQjUDzHnzyw"}},{"cell_type":"markdown","source":"### 6. LoRA Tuning with PEFT","metadata":{"id":"C1EsZPhknzyx"}},{"cell_type":"markdown","source":"Fine-tune the model using the Trainer API from Hugging Face.","metadata":{"id":"M1TtHv0Unzyx"}},{"cell_type":"code","source":"# Check if GPU is available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Load evaluation metrics\nprecision_metric = evaluate.load(\"precision\", trust_remote_code=True)\nrecall_metric = evaluate.load(\"recall\", trust_remote_code=True)\nf1_metric = evaluate.load(\"f1\", trust_remote_code=True)\n\n# Function to compute evaluation metrics\ndef compute_metrics(p):\n    predictions, labels = p\n    predictions = np.argmax(predictions, axis=1)\n    accuracy = (predictions == labels).astype(np.float32).mean().item()\n    precision = precision_metric.compute(predictions=predictions, references=labels)['precision']\n    recall = recall_metric.compute(predictions=predictions, references=labels)['recall']\n    f1 = f1_metric.compute(predictions=predictions, references=labels)['f1']\n    return {\n        'accuracy': accuracy,\n        'precision': precision,\n        'recall': recall,\n        'f1': f1\n    }\n\n# Define training arguments\ntraining_args = TrainingArguments(\n    output_dir='./results',\n    evaluation_strategy=\"epoch\",\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    logging_dir='./logs',\n    logging_steps=10,\n    no_cuda=not torch.cuda.is_available() # Ensure the GPU is utilized if available\n)\n\n# Initialize the Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=encoded_train_dataset,\n    eval_dataset=encoded_test_dataset,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics\n)\n\n# Train the model\ntrainer.train()","metadata":{"id":"JKp6zPv5nzyx","outputId":"77df69d7-51e5-4eee-878f-217dcd11e528","execution":{"iopub.status.busy":"2024-05-30T14:10:32.003511Z","iopub.execute_input":"2024-05-30T14:10:32.003876Z","iopub.status.idle":"2024-05-30T14:41:06.677742Z","shell.execute_reply.started":"2024-05-30T14:10:32.003844Z","shell.execute_reply":"2024-05-30T14:41:06.676845Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='4689' max='4689' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [4689/4689 30:31, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.447100</td>\n      <td>No log</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.431500</td>\n      <td>No log</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.374200</td>\n      <td>No log</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=4689, training_loss=0.44037046969432675, metrics={'train_runtime': 1832.2125, 'train_samples_per_second': 81.868, 'train_steps_per_second': 2.559, 'total_flos': 9917625369600000.0, 'train_loss': 0.44037046969432675, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"markdown","source":"### 7. Evaluation and Analysis","metadata":{"id":"NUSxB05Ynzyx"}},{"cell_type":"markdown","source":"Evaluate the model on the test set and analyze the results.","metadata":{"id":"TJTn4ywvnzyx"}},{"cell_type":"code","source":"# Evaluate the model\neval_results = trainer.evaluate()\nprint(eval_results)","metadata":{"id":"udMO_vNenzyy","outputId":"99cd8bd7-a949-4cd6-9dca-97a21dcca55e","execution":{"iopub.status.busy":"2024-05-30T14:41:11.732090Z","iopub.execute_input":"2024-05-30T14:41:11.732504Z","iopub.status.idle":"2024-05-30T14:42:07.301616Z","shell.execute_reply.started":"2024-05-30T14:41:11.732470Z","shell.execute_reply":"2024-05-30T14:42:07.300471Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='313' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [313/313 00:55]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"{'eval_runtime': 55.5562, 'eval_samples_per_second': 179.998, 'eval_steps_per_second': 5.634, 'epoch': 3.0}\n","output_type":"stream"}]},{"cell_type":"code","source":"# Analyze the results\ndef predict(question1, question2, eval_model):\n    inputs = tokenizer(question1, question2, return_tensors='pt', truncation=True, padding='max_length', max_length=128).to(device)\n    with torch.no_grad():\n        logits = eval_model(**inputs).logits\n    probabilities = torch.nn.functional.softmax(logits, dim=-1)\n    return probabilities","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test the model with different pairs of questions\nexamples = [\n    (\"How do I cook pasta?\", \"What is the process of cooking pasta?\"),\n    (\"How to boil an egg?\", \"What is the best way to cook an egg?\"),\n    (\"What is machine learning?\", \"Can you explain artificial intelligence?\"),\n    (\"What are the symptoms of COVID-19?\", \"How do I know if I have coronavirus?\")\n]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict and print the results for each example with the fine tuned model\nfor question1, question2 in examples:\n    probabilities = predict(question1, question2, model)\n    print(f\"Question 1: {question1}\")\n    print(f\"Question 2: {question2}\")\n    print(f\"Probabilities: {probabilities}\")\n    predicted_label = torch.argmax(probabilities, dim=-1).item()\n    label_names = [\"Not Paraphrase\", \"Paraphrase\"]\n    print(f\"Predicted Label: {label_names[predicted_label]}\")\n    print()","metadata":{"id":"CNwRNPqB0lUb","outputId":"c958967c-7da1-4cbd-9b33-f04629939760","execution":{"iopub.status.busy":"2024-05-30T14:47:15.755871Z","iopub.execute_input":"2024-05-30T14:47:15.756562Z","iopub.status.idle":"2024-05-30T14:47:15.848145Z","shell.execute_reply.started":"2024-05-30T14:47:15.756528Z","shell.execute_reply":"2024-05-30T14:47:15.847241Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Question 1: How do I cook pasta?\nQuestion 2: What is the process of cooking pasta?\nProbabilities: tensor([[0.3129, 0.6871]], device='cuda:0')\nPredicted Label: Paraphrase\n\nQuestion 1: How to boil an egg?\nQuestion 2: What is the best way to cook an egg?\nProbabilities: tensor([[0.3249, 0.6751]], device='cuda:0')\nPredicted Label: Paraphrase\n\nQuestion 1: What is machine learning?\nQuestion 2: Can you explain artificial intelligence?\nProbabilities: tensor([[0.9623, 0.0377]], device='cuda:0')\nPredicted Label: Not Paraphrase\n\nQuestion 1: What are the symptoms of COVID-19?\nQuestion 2: How do I know if I have coronavirus?\nProbabilities: tensor([[0.9694, 0.0306]], device='cuda:0')\nPredicted Label: Not Paraphrase\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load a pre-trained model ffrom scratch.\nmodel_pretrained = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2).to(device)\n\n# Predict and print the results for each example with the pre-trained model\nfor question1, question2 in examples:\n    probabilities = predict(question1, question2, model_pretrained)\n    print(f\"Question 1: {question1}\")\n    print(f\"Question 2: {question2}\")\n    print(f\"Probabilities: {probabilities}\")\n    predicted_label = torch.argmax(probabilities, dim=-1).item()\n    label_names = [\"Not Paraphrase\", \"Paraphrase\"]\n    print(f\"Predicted Label: {label_names[predicted_label]}\")\n    print()","metadata":{"execution":{"iopub.status.busy":"2024-05-30T14:48:36.173831Z","iopub.execute_input":"2024-05-30T14:48:36.174208Z","iopub.status.idle":"2024-05-30T14:48:36.692536Z","shell.execute_reply.started":"2024-05-30T14:48:36.174177Z","shell.execute_reply":"2024-05-30T14:48:36.691430Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Question 1: How do I cook pasta?\nQuestion 2: What is the process of cooking pasta?\nProbabilities: tensor([[0.5031, 0.4969]], device='cuda:0')\nPredicted Label: Not Paraphrase\n\nQuestion 1: How to boil an egg?\nQuestion 2: What is the best way to cook an egg?\nProbabilities: tensor([[0.5017, 0.4983]], device='cuda:0')\nPredicted Label: Not Paraphrase\n\nQuestion 1: What is machine learning?\nQuestion 2: Can you explain artificial intelligence?\nProbabilities: tensor([[0.5130, 0.4870]], device='cuda:0')\nPredicted Label: Not Paraphrase\n\nQuestion 1: What are the symptoms of COVID-19?\nQuestion 2: How do I know if I have coronavirus?\nProbabilities: tensor([[0.5132, 0.4868]], device='cuda:0')\nPredicted Label: Not Paraphrase\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Conclusion","metadata":{"id":"zJ9KNgHinzyy"}},{"cell_type":"markdown","source":"In this notebook, we have covered the process of fine-tuning a pre-trained language model using LoRA with the PEFT library from Hugging Face.In the last section we evaluated the fine tuned model vs. pre-trained model. As expected pre-trained model gave almost random results, because it is not trained accordingly at the beginning, After fine tuning, the model started to give better results but not the bests. This is because it can be trained more epochs and with more data.","metadata":{"id":"UX8B6FL9nzyy"}},{"cell_type":"markdown","source":"## Additional Resources","metadata":{"id":"KemkLfmNnzyy"}},{"cell_type":"markdown","source":"- The original paper on arXiv: [LoRA: Low-Rank Adaptation of Large Language Models](https://arxiv.org/abs/2106.09685)\n\n- Hugging Face LoRA apapter: [Hugging Face](https://huggingface.co/docs/peft/package_reference/lora)","metadata":{"id":"1C-AYRpsnzyy"}}]}